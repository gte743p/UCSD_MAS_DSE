{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Evaluate Modeling Approaches on Validation Data\n",
    "1. Get processed modeling data from database\n",
    "2. Model Stage 1 - level_binary\n",
    "3. Model Stage 2 - multiclass level\n",
    "4. Calculate performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2 as pg\n",
    "import datetime as dt\n",
    "from sklearn import preprocessing\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import cPickle as pickle\n",
    "import gc\n",
    "import socket\n",
    "import boto3\n",
    "from boto.utils import get_instance_metadata\n",
    "import ast\n",
    "from Segments import Segments\n",
    "from Times import Times\n",
    "from Cluster import Cluster\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import joblib\n",
    "import string\n",
    "from AWS import AWS\n",
    "from Utility import Utility\n",
    "\n",
    "# clustering\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# modeling\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set environment\n",
    "\n",
    "aws = None\n",
    "s3_bucket_name = 'dse-cohort3-group3'\n",
    "s3_dat_dir = 'PreprocessedWazeData'\n",
    "\n",
    "# assume connection file is always present\n",
    "conn_str_file = '../conf/db_conn_str.txt'\n",
    "sampling_args_file = '../conf/pipeline_args.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fr = open(sampling_args_file, 'r')\n",
    "fa = fr.read()\n",
    "file_args = ast.literal_eval(fa)\n",
    "file_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume save_dir already exists\n",
    "save_dir = file_args['save_dir']\n",
    "save_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. get data from db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_data_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create AWS object and helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "util = Utility(file_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if util.isAWS():\n",
    "    aws = AWS(s3_bucket_name, s3_dat_dir)\n",
    "\n",
    "pg_conn_str = open(conn_str_file, 'r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### connect to database and get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = pg.connect(pg_conn_str) \n",
    "util.conn = conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = util.get_modeling_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- getting data took {0:.1f} seconds ---'.format(time.time() - get_data_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modeling_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.  first modeling stage - level_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_modeling_stage_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create prediction dataframes\n",
    "targets = [c for c in train_data.columns if c.startswith('level')]\n",
    "train_preds = train_data[['date','time','date_idx','time_idx','segment_id','day_of_week','cluster']+targets].copy()\n",
    "test_preds = test_data[['date','time','date_idx','time_idx','segment_id','day_of_week','cluster']+targets].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dicts to track validation results\n",
    "val_results_dict = {\n",
    "    'stage_1': {},\n",
    "    'stage_2': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps = util.get_validation_splits(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set f1_score average parameter\n",
    "f1_avg = 'binary' if file_args['scoring_metric'] == 'f1' else str.replace(file_args['scoring_metric'], 'f1_','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stage 1 avg baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate validation f1 scores for choosing best model for cluster ensemble\n",
    "if file_args['model_avg_baseline']:\n",
    "    print('calculating validation scores for average baseline...')\n",
    "    pred_suffix = '_preds_avg_baseline'\n",
    "    \n",
    "    # create dict to store local results\n",
    "    model_val_results = {k:np.array([]) for k in train_data['cluster'].unique()}\n",
    "    \n",
    "    # split data into trn and val and calculate prediction scores\n",
    "    splits = ps.split() if file_args['train_test_method']=='date' else ps.split(train_data, train_data[file_args['target_first_stage']])\n",
    "    for idx, (trn_idx, val_idx) in enumerate(splits):\n",
    "        print('validation fold {}...'.format(idx))\n",
    "        X_t, X_v = train_data.iloc[trn_idx,:], train_data.iloc[val_idx,:]\n",
    "    \n",
    "        # calculate average of target for time, segment, dow groups\n",
    "        y_trn_avg = X_t.groupby(['time_idx', 'segment_id', 'day_of_week'],as_index=False)[file_args['target_first_stage']].mean()\n",
    "\n",
    "        # make prediction for time/segment based on target average\n",
    "        y_preds_avg = y_trn_avg[['time_idx','segment_id','day_of_week',file_args['target_first_stage']]].copy()\n",
    "        y_preds_avg = y_preds_avg.round({file_args['target_first_stage']: 0})\n",
    "        y_preds_avg.rename(columns={file_args['target_first_stage']:file_args['target_first_stage']+pred_suffix}, inplace=True)\n",
    "\n",
    "        # join predictions to train and val dataframes\n",
    "        train_preds_avg = X_t.merge(y_preds_avg, how='left', on=['time_idx','segment_id','day_of_week'])\n",
    "        val_preds_avg = X_v.merge(y_preds_avg, how='left', on=['time_idx','segment_id','day_of_week'])\n",
    "\n",
    "        # fill null predictions with 0\n",
    "        train_preds_avg[file_args['target_first_stage']+pred_suffix].fillna(value=0, inplace=True)\n",
    "        val_preds_avg[file_args['target_first_stage']+pred_suffix].fillna(value=0, inplace=True)\n",
    "\n",
    "        # calculate f1 scores for individual clusters for this val fold\n",
    "        for clust in X_t['cluster'].unique():\n",
    "            tmp_val_clust = val_preds_avg[val_preds_avg['cluster']==clust]\n",
    "            tmp_val_preds = tmp_val_clust[file_args['target_first_stage']]\n",
    "            tmp_val_actuals = tmp_val_clust[file_args['target_first_stage']+pred_suffix]\n",
    "        \n",
    "            val_f1 = f1_score(tmp_val_actuals, tmp_val_preds, average=f1_avg)\n",
    "\n",
    "            # update model_val_metrics\n",
    "            model_val_results[clust] = np.append(model_val_results[clust], val_f1)\n",
    "            \n",
    "    # calculate avg f1 scores from multiple validation sets\n",
    "    for key in model_val_results:\n",
    "        model_val_results[key] = model_val_results[key].mean()        \n",
    "\n",
    "    # add model val results to dict\n",
    "    val_results_dict['stage_1']['model_avg_baseline'] = model_val_results\n",
    "\n",
    "    # save averages \"model\" (dataframe for merging later) for full training data\n",
    "    y_trn_avg = train_data.groupby(['time_idx', 'segment_id', 'day_of_week'],as_index=False)[file_args['target_first_stage']].mean()\n",
    "    y_preds_avg = y_trn_avg[['time_idx','segment_id','day_of_week',file_args['target_first_stage']]].copy()\n",
    "    y_preds_avg = y_preds_avg.round({file_args['target_first_stage']: 0})\n",
    "    y_preds_avg.rename(columns={file_args['target_first_stage']:file_args['target_first_stage']+pred_suffix}, inplace=True)\n",
    "    fn = os.path.join(save_dir, 'stage1_model_avg_baseline.pkl')\n",
    "    joblib.dump(y_preds_avg, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stage 1 non-baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'random_forest': RandomForestClassifier(random_state=file_args['seed']),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    'extra_trees': ExtraTreesClassifier(random_state=file_args['seed']),\n",
    "    'gradient_boosting': GradientBoostingClassifier(random_state=file_args['seed']),\n",
    "    'logistic_regression': LogisticRegression(random_state=file_args['seed']),\n",
    "    'gaussian_nb': GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_stage1_model_on_full(model_key):\n",
    "    if file_args['model_full_{}'.format(model_key)]:\n",
    "        print('training {} on full data...'.format(model_key))\n",
    "        model = model_dict[model_key]\n",
    "        pred_suffix = '_preds_full_{}'.format(model_key)\n",
    "\n",
    "        # split features and targets\n",
    "        level_cols = [c for c in train_data.columns if c.startswith('level')]\n",
    "        X_trn = train_data.drop(labels=['date','time']+level_cols, axis=1)\n",
    "        Y_trn = train_data.loc[:,file_args['target_first_stage']].values.ravel()\n",
    "\n",
    "        # create dict to store local results\n",
    "        model_val_results = {k:np.array([]) for k in train_data['cluster'].unique()}\n",
    "\n",
    "        # split data into trn and val and calculate prediction scores\n",
    "        splits = ps.split() if file_args['train_test_method']=='date' else ps.split(X_trn, Y_trn)\n",
    "        for idx, (trn_idx, val_idx) in enumerate(splits):\n",
    "            print('validation fold {}...'.format(idx))\n",
    "            X_val = X_trn.iloc[val_idx,:]\n",
    "            X_t = X_trn.iloc[trn_idx,:].drop(labels='cluster', axis=1)\n",
    "            X_v = X_trn.iloc[val_idx,:].drop(labels='cluster', axis=1)\n",
    "            Y_t, Y_v = Y_trn[trn_idx], Y_trn[val_idx]\n",
    "\n",
    "            model.fit(X_t, Y_t)\n",
    "            val_preds = model.predict(X_v)\n",
    "\n",
    "            # calculate scores for individual clusters for this val fold\n",
    "            for clust in train_data['cluster'].unique():\n",
    "                tmp_val_preds = val_preds[X_val['cluster']==clust]\n",
    "                tmp_val_actuals = Y_v[X_val['cluster']==clust]\n",
    "                val_f1_clust = f1_score(tmp_val_actuals, tmp_val_preds, average=f1_avg)\n",
    "\n",
    "                # update model_val_metrics\n",
    "                model_val_results[clust] = np.append(model_val_results[clust], val_f1_clust)\n",
    "\n",
    "            # fit model on full train+val data and save model\n",
    "            if idx == 0:\n",
    "                X = pd.concat([X_t, X_v])\n",
    "                Y = np.append(Y_t, Y_v)\n",
    "                model.fit(X, Y)\n",
    "                fn = os.path.join(save_dir, 'stage1_model_full_{}.pkl'.format(model_key))\n",
    "                joblib.dump(model, fn)\n",
    "\n",
    "        # calculate avg f1 scores from multiple validation sets\n",
    "        for key in model_val_results:\n",
    "            model_val_results[key] = model_val_results[key].mean()\n",
    "\n",
    "        # add model val results to dict\n",
    "        val_results_dict['stage_1']['model_full_{}'.format(model_key)] = model_val_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_stage1_model_on_clusters(model_key):\n",
    "    if file_args['model_clusters_{}'.format(model_key)]:\n",
    "        print('training {} on clustered data...'.format(model_key))\n",
    "        model = model_dict[model_key]   \n",
    "        pred_suffix = '_preds_cluster_{}'.format(model_key)\n",
    "\n",
    "        # create dict to store local results\n",
    "        model_val_results = {k:np.array([]) for k in train_data['cluster'].unique()}\n",
    "\n",
    "        # split data into trn and val and calculate prediction scores\n",
    "        splits = ps.split() if file_args['train_test_method']=='date' else ps.split(train_data, train_data[file_args['target_first_stage']])\n",
    "        for idx, (trn_idx, val_idx) in enumerate(splits):\n",
    "            print('validation fold {}...'.format(idx))\n",
    "            trn_data = train_data.iloc[trn_idx,:]\n",
    "            val_data = train_data.iloc[val_idx,:]\n",
    "\n",
    "            for clust in train_data['cluster'].unique():\n",
    "                # subset data to cluster\n",
    "                train_clust = trn_data[trn_data['cluster']==clust]\n",
    "                val_clust = val_data[val_data['cluster']==clust]\n",
    "\n",
    "                # calculate negative to positive ratio for each cluster\n",
    "                trn_clust_ratio = util.get_neg_pos_ratio(train_clust)\n",
    "                val_clust_ratio = util.get_neg_pos_ratio(val_clust)\n",
    "\n",
    "                # unskew individual clusters\n",
    "                if (file_args['unskew_train_clusters'] and trn_ratio > file_args['unskew_ratio']):\n",
    "                    print('unskewing train data to negative positive ratio of {}...'.format(file_args['unskew_ratio']))\n",
    "                    train_clust = util.unskew_data(train_clust, file_args['unskew_ratio'])\n",
    "                if (file_args['unskew_test'] and val_ratio > file_args['unskew_ratio']):\n",
    "                    print('unskewing val data to negative positive ratio of {}...'.format(file_args['unskew_ratio']))\n",
    "                    val_clust = util.unskew_data(val_clust, file_args['unskew_ratio'])\n",
    "\n",
    "                # split features and targets\n",
    "                level_cols = [col for col in train_data.columns if col.startswith('level')]\n",
    "                X_trn = train_clust.drop(labels=['date','time','cluster']+level_cols, axis=1)\n",
    "                Y_trn = train_clust.loc[:,file_args['target_first_stage']].values.ravel()\n",
    "                X_val = val_clust.drop(labels=['date','time','cluster']+level_cols, axis=1)\n",
    "                Y_val = val_clust.loc[:,file_args['target_first_stage']].values.ravel()\n",
    "\n",
    "                # fit model\n",
    "                model.fit(X_trn, Y_trn)\n",
    "\n",
    "                # make predictions\n",
    "                val_preds = model.predict(X_val)\n",
    "\n",
    "                # calculate f1 score for cluster and append actuals and predictions to list\n",
    "                val_f1_clust = f1_score(Y_val, val_preds, average=f1_avg)\n",
    "                model_val_results[clust] = np.append(model_val_results[clust], val_f1_clust)\n",
    "\n",
    "                # fit model on full train+val data and save model\n",
    "                if idx == 0:\n",
    "                    X = pd.concat([X_trn, X_val])\n",
    "                    Y = np.append(Y_trn, Y_val)\n",
    "                    model.fit(X, Y)\n",
    "                    fn = os.path.join(save_dir, 'stage1_model_clusters_{}_cluster_{}.pkl'.format(model_key, clust))\n",
    "                    joblib.dump(model, fn)\n",
    "\n",
    "        # calculate avg f1 scores from multiple validation sets\n",
    "        for key in model_val_results:\n",
    "            model_val_results[key] = model_val_results[key].mean()\n",
    "\n",
    "        # add model val results to dict\n",
    "        val_results_dict['stage_1']['model_clusters_{}'.format(model_key)] = model_val_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for model_key in model_dict.keys():\n",
    "    fit_stage1_model_on_full(model_key)\n",
    "    fit_stage1_model_on_clusters(model_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add cluster counts\n",
    "clust_count_dict = {}\n",
    "for clust in train_data['cluster'].unique():\n",
    "    clust_count_dict[clust] = train_data[train_data['cluster']==clust].shape[0]\n",
    "    \n",
    "val_results_dict['stage_1']['cluster_counts'] = clust_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- first modeling stage took {0:.1f} seconds ---'.format(time.time() - first_modeling_stage_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1  second modeling stage - non-binary level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "second_modeling_stage_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset train data to only include existence of traffic\n",
    "train_data_pos = train_data[train_data['level_binary'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get predefined splits for positive data only\n",
    "ps_pos = util.get_validation_splits(train_data_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stage 2 average baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate validation scores\n",
    "if file_args['model_avg_baseline']:\n",
    "    print('calculating validation scores for average baseline...')\n",
    "    pred_suffix = '_preds_avg_baseline'\n",
    "    \n",
    "    # create dict to store local results\n",
    "    model_val_results = {k:np.array([]) for k in train_data_pos['cluster'].unique()}\n",
    "    \n",
    "    # split data into trn and val and calculate prediction scores\n",
    "    splits = ps_pos.split() if file_args['train_test_method']=='date' else ps_pos.split(train_data_pos, train_data_pos[file_args['target_second_stage']])\n",
    "    for idx, (trn_idx, val_idx) in enumerate(splits):\n",
    "        print('validation fold {}...'.format(idx))\n",
    "        X_t, X_v = train_data_pos.iloc[trn_idx,:], train_data_pos.iloc[val_idx,:]\n",
    "    \n",
    "        # calculate average of target for time, segment, dow groups\n",
    "        y_trn_avg = X_t.groupby(['time_idx', 'segment_id', 'day_of_week'],as_index=False)[file_args['target_second_stage']].mean()\n",
    "\n",
    "        # make prediction for time/segment based on target average\n",
    "        y_preds_avg = y_trn_avg[['time_idx','segment_id','day_of_week',file_args['target_second_stage']]].copy()\n",
    "        y_preds_avg = y_preds_avg.round({file_args['target_second_stage']: 0})\n",
    "        y_preds_avg.rename(columns={file_args['target_second_stage']:file_args['target_second_stage']+pred_suffix}, inplace=True)\n",
    "\n",
    "        # join predictions to train and val dataframes\n",
    "        train_preds_avg = X_t.merge(y_preds_avg, how='left', on=['time_idx','segment_id','day_of_week'])\n",
    "        val_preds_avg = X_v.merge(y_preds_avg, how='left', on=['time_idx','segment_id','day_of_week'])\n",
    "\n",
    "        # fill null predictions with 0\n",
    "        train_preds_avg[file_args['target_second_stage']+pred_suffix].fillna(value=0, inplace=True)\n",
    "        val_preds_avg[file_args['target_second_stage']+pred_suffix].fillna(value=0, inplace=True)\n",
    "\n",
    "        # set stage 2 predictions to 0 if stage 'level_binary' prediction was 0\n",
    "        y_trn_bin_avg = X_t.groupby(['time_idx', 'segment_id', 'day_of_week'],as_index=False)['level_binary'].mean()\n",
    "        y_preds_bin_avg = y_trn_bin_avg[['time_idx','segment_id','day_of_week','level_binary']].copy()\n",
    "        y_preds_bin_avg = y_preds_bin_avg.round({file_args['target_second_stage']: 0})\n",
    "        y_preds_bin_avg.rename(columns={'level_binary':'level_binary_pred'}, inplace=True)\n",
    "        train_preds_avg = train_preds_avg.merge(y_preds_bin_avg, how='left', on=['time_idx','segment_id','day_of_week'])\n",
    "        val_preds_avg = val_preds_avg.merge(y_preds_bin_avg, how='left', on=['time_idx','segment_id','day_of_week'])\n",
    "        train_preds_avg['level_binary_pred'].fillna(value=0, inplace=True)\n",
    "        val_preds_avg['level_binary_pred'].fillna(value=0, inplace=True)\n",
    "        \n",
    "        train_preds_avg.loc[:, file_args['target_second_stage']+pred_suffix] \\\n",
    "            = train_preds_avg[file_args['target_second_stage']+pred_suffix] \\\n",
    "            * train_preds_avg['level_binary_pred']\n",
    "        val_preds_avg.loc[:, file_args['target_second_stage']+pred_suffix] \\\n",
    "            = val_preds_avg[file_args['target_second_stage']+pred_suffix] \\\n",
    "            * val_preds_avg['level_binary_pred']\n",
    "        \n",
    "        # calculate f1 scores for individual clusters for this val fold\n",
    "        for clust in X_t['cluster'].unique():\n",
    "            tmp_val_clust = val_preds_avg[val_preds_avg['cluster']==clust]\n",
    "            tmp_val_preds = tmp_val_clust[file_args['target_second_stage']]\n",
    "            tmp_val_actuals = tmp_val_clust[file_args['target_second_stage']+pred_suffix]\n",
    "        \n",
    "            val_f1 = f1_score(tmp_val_actuals, tmp_val_preds, average=f1_avg)\n",
    "\n",
    "            # update model_val_metrics\n",
    "            model_val_results[clust] = np.append(model_val_results[clust], val_f1)\n",
    "            \n",
    "    # calculate avg f1 scores from multiple validation sets\n",
    "    for key in model_val_results:\n",
    "        model_val_results[key] = model_val_results[key].mean()\n",
    "\n",
    "    # add model val results to dict\n",
    "    val_results_dict['stage_2']['model_avg_baseline'] = model_val_results\n",
    "\n",
    "    # save averages \"model\" (dataframe for merging later) for full training data\n",
    "    y_trn_avg = train_data_pos.groupby(['time_idx', 'segment_id', 'day_of_week'],as_index=False)[file_args['target_second_stage']].mean()\n",
    "    y_preds_avg = y_trn_avg[['time_idx','segment_id','day_of_week',file_args['target_second_stage']]].copy()\n",
    "    y_preds_avg = y_preds_avg.round({file_args['target_second_stage']: 0})\n",
    "    y_preds_avg.rename(columns={file_args['target_second_stage']:file_args['target_second_stage']+pred_suffix}, inplace=True)\n",
    "    fn = os.path.join(save_dir, 'stage2_model_avg_baseline.pkl')\n",
    "    joblib.dump(y_preds_avg, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stage 2 non-baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_stage2_model_on_full(model_key):\n",
    "    if file_args['model_full_{}'.format(model_key)]:\n",
    "        print('training {} on full data...'.format(model_key))\n",
    "        model = model_dict[model_key]\n",
    "        pred_suffix = '_preds_full_{}'.format(model_key)\n",
    "\n",
    "        # split features and targets\n",
    "        level_cols = [c for c in train_data_pos.columns if c.startswith('level')]\n",
    "        X_trn = train_data_pos.drop(labels=['date','time']+level_cols, axis=1)\n",
    "        Y_trn = train_data_pos.loc[:,file_args['target_second_stage']].values.ravel()\n",
    "\n",
    "        # create dict to store local results\n",
    "        model_val_results = {k:np.array([]) for k in train_data_pos['cluster'].unique()}\n",
    "\n",
    "        # split data into trn and val and calculate prediction scores\n",
    "        splits = ps_pos.split() if file_args['train_test_method']=='date' else ps_pos.split(X_trn, Y_trn)\n",
    "        for idx, (trn_idx, val_idx) in enumerate(splits):\n",
    "            print('validation fold {}...'.format(idx))\n",
    "            X_val = X_trn.iloc[val_idx,:]\n",
    "            X_t = X_trn.iloc[trn_idx,:].drop(labels='cluster', axis=1)\n",
    "            X_v = X_trn.iloc[val_idx,:].drop(labels='cluster', axis=1)\n",
    "            Y_t, Y_v = Y_trn[trn_idx], Y_trn[val_idx]\n",
    "\n",
    "            model.fit(X_t, Y_t)\n",
    "            val_preds = model.predict(X_v)\n",
    "\n",
    "            # calculate scores for individual clusters for this val fold\n",
    "            for clust in train_data_pos['cluster'].unique():\n",
    "                tmp_val_preds = val_preds[X_val['cluster']==clust]\n",
    "                tmp_val_actuals = Y_v[X_val['cluster']==clust]\n",
    "                val_f1_clust = f1_score(tmp_val_actuals, tmp_val_preds, average=f1_avg)\n",
    "\n",
    "                # update model_val_metrics\n",
    "                model_val_results[clust] = np.append(model_val_results[clust], val_f1_clust)\n",
    "\n",
    "            # fit model on full train+val data and save model\n",
    "            if idx == 0:\n",
    "                X = pd.concat([X_t, X_v])\n",
    "                Y = np.append(Y_t, Y_v)\n",
    "                model.fit(X, Y)\n",
    "                fn = os.path.join(save_dir, 'stage2_model_full_{}.pkl'.format(model_key))\n",
    "                joblib.dump(model, fn)\n",
    "\n",
    "        # calculate avg f1 scores from multiple validation sets\n",
    "        for key in model_val_results:\n",
    "            model_val_results[key] = model_val_results[key].mean()\n",
    "\n",
    "        # add model val results to dict\n",
    "        val_results_dict['stage_2']['model_full_{}'.format(model_key)] = model_val_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_stage2_model_on_clusters(model_key):\n",
    "    if file_args['model_clusters_{}'.format(model_key)]:\n",
    "        print('training {} on clustered data...'.format(model_key))\n",
    "        model = model_dict[model_key]\n",
    "        pred_suffix = '_preds_cluster_{}'.format(model_key)\n",
    "\n",
    "        # create dict to store local results\n",
    "        model_val_results = {k:np.array([]) for k in train_data_pos['cluster'].unique()}\n",
    "\n",
    "        # split data into trn and val and calculate prediction scores\n",
    "        splits = ps_pos.split() if file_args['train_test_method']=='date' else ps_pos.split(train_data_pos, train_data_pos[file_args['target_second_stage']])\n",
    "        for idx, (trn_idx, val_idx) in enumerate(splits):\n",
    "            print('validation fold {}...'.format(idx))\n",
    "            trn_data = train_data_pos.iloc[trn_idx,:]\n",
    "            val_data = train_data_pos.iloc[val_idx,:]\n",
    "\n",
    "            for clust in train_data_pos['cluster'].unique():\n",
    "\n",
    "                # subset data to cluster\n",
    "                train_clust = trn_data[trn_data['cluster']==clust]\n",
    "                val_clust = val_data[val_data['cluster']==clust]\n",
    "\n",
    "                # calculate negative to positive ratio for each cluster\n",
    "                trn_clust_ratio = util.get_neg_pos_ratio(train_clust)\n",
    "                val_clust_ratio = util.get_neg_pos_ratio(val_clust)\n",
    "\n",
    "                # unskew individual clusters\n",
    "                if (file_args['unskew_train_clusters'] and trn_ratio > file_args['unskew_ratio']):\n",
    "                    print('unskewing train data to negative positive ratio of {}...'.format(file_args['unskew_ratio']))\n",
    "                    train_clust = util.unskew_data(train_clust, file_args['unskew_ratio'])\n",
    "                if (file_args['unskew_test'] and val_ratio > file_args['unskew_ratio']):\n",
    "                    print('unskewing val data to negative positive ratio of {}...'.format(file_args['unskew_ratio']))\n",
    "                    val_clust = util.unskew_data(val_clust, file_args['unskew_ratio'])\n",
    "\n",
    "                # split features and targets\n",
    "                level_cols = [col for col in train_data_pos.columns if col.startswith('level')]\n",
    "                X_trn = train_clust.drop(labels=['date','time','cluster']+level_cols, axis=1)\n",
    "                Y_trn = train_clust.loc[:,file_args['target_second_stage']].values.ravel()\n",
    "                X_val = val_clust.drop(labels=['date','time','cluster']+level_cols, axis=1)\n",
    "                Y_val = val_clust.loc[:,file_args['target_second_stage']].values.ravel()\n",
    "\n",
    "                # fit model\n",
    "                model.fit(X_trn, Y_trn)\n",
    "\n",
    "                # make predictions\n",
    "                val_preds = model.predict(X_val)\n",
    "\n",
    "                # calculate f1 score for cluster and append actuals and predictions to list\n",
    "                val_f1_clust = f1_score(Y_val, val_preds, average=f1_avg)\n",
    "                model_val_results[clust] = np.append(model_val_results[clust], val_f1_clust)\n",
    "\n",
    "                # fit model on full train+val data and save model\n",
    "                if idx == 0:\n",
    "                    X = pd.concat([X_trn, X_val])\n",
    "                    Y = np.append(Y_trn, Y_val)\n",
    "                    model.fit(X, Y)\n",
    "                    fn = os.path.join(save_dir, 'stage2_model_clusters_{}_cluster_{}.pkl'.format(model_key, clust))\n",
    "                    joblib.dump(model, fn)\n",
    "\n",
    "        # calculate avg f1 scores from multiple validation sets\n",
    "        for key in model_val_results:\n",
    "            model_val_results[key] = model_val_results[key].mean()\n",
    "\n",
    "        # add model val results to dict\n",
    "        val_results_dict['stage_2']['model_clusters_{}'.format(model_key)] = model_val_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_key in model_dict.keys():\n",
    "    fit_stage2_model_on_full(model_key)\n",
    "    fit_stage2_model_on_clusters(model_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add cluster counts\n",
    "clust_count_dict = {}\n",
    "for clust in train_data_pos['cluster'].unique():\n",
    "    clust_count_dict[clust] = train_data_pos[train_data_pos['cluster']==clust].shape[0]\n",
    "    \n",
    "val_results_dict['stage_2']['cluster_counts'] = clust_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- second modeling stage took {0:.1f} seconds ---'.format(time.time() - second_modeling_stage_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_results_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "util.add_best_models(val_results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save val_results_dict\n",
    "fn = os.path.join(save_dir, 'val_results_dict.pkl')\n",
    "joblib.dump(val_results_dict, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.metrics_plot_model(val_results_dict, stage='stage_1', score_metric=file_args['scoring_metric'], \n",
    "                        sort=True, title_prefix='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.metrics_plot_model(val_results_dict, stage='stage_2', score_metric=file_args['scoring_metric'], \n",
    "                        sort=True, title_prefix='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- evaluating results took {0:.1f} seconds ---'.format(time.time() - eval_results_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- entire pipeline took {0:.1f} seconds ---'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Phase 1 - Averages.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
