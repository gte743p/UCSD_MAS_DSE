{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSE220 Final Model Analysis Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict, Counter\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import pca\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read original files\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "orig_train_df = getDF('train.json.gz')\n",
    "orig_test_df = getDF('test_Helpful.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshwilson/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# split outOf and nHelpful out as separate columns\n",
    "train_outOf = np.array([x['outOf'] for x in orig_train_df.helpful.values])\n",
    "train_nHelpful = np.array([x['nHelpful'] for x in orig_train_df.helpful.values])\n",
    "orig_train_df['outOf'] = train_outOf\n",
    "orig_train_df['nHelpful'] = train_nHelpful\n",
    "orig_train_df['pctHelpful'] = train_nHelpful / train_outOf\n",
    "\n",
    "test_outOf = np.array([x['outOf'] for x in orig_test_df.helpful.values])\n",
    "orig_test_df['outOf'] = test_outOf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read preprocessed csv files\n",
    "train = pd.read_csv('train.csv')\n",
    "val = pd.read_csv('val.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50529, 229)\n",
      "(12486, 229)\n",
      "(4400, 227)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### prepare files to use for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000, 15) (40000, 15) (14000, 13)\n",
      "(160000, 2) (40000, 2) (14000, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, X_val_orig = train_test_split(orig_train_df, test_size=0.20, random_state=55)\n",
    "print(X_train_orig.shape, X_val_orig.shape, orig_test_df.shape)\n",
    "\n",
    "X_train_sub_template = X_train_orig.loc[:,['reviewerID','itemID']]\n",
    "X_val_sub_template = X_val_orig.loc[:,['reviewerID','itemID']]\n",
    "X_test_sub_template = orig_test_df.loc[:,['reviewerID','itemID']]\n",
    "print(X_train_sub_template.shape, X_val_sub_template.shape, X_test_sub_template.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare train dataset prediction dataframe\n",
    "X_train_pred = train.loc[:,['reviewerID','itemID','outOf','nHelpful']]\n",
    "\n",
    "# extract info\n",
    "y_train_pctHelpful = train.loc[:,'pctHelpful']\n",
    "y_train_nHelpful = train.loc[:,'nHelpful']\n",
    "y_train_outOf = train.loc[:,'outOf']\n",
    "\n",
    "# drop categorical columns\n",
    "X_train_num = train.drop(labels=['reviewerID','itemID','nHelpful','pctHelpful'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare validation dataset predicion dataframe\n",
    "X_val_pred = val.loc[:,['reviewerID','itemID','outOf','nHelpful']]\n",
    "\n",
    "# extract info\n",
    "y_val_pctHelpful = val.loc[:,'pctHelpful']\n",
    "y_val_nHelpful = val.loc[:,'nHelpful']\n",
    "y_val_outOf = val.loc[:,'outOf']\n",
    "\n",
    "# drop categorical columns and answers\n",
    "X_val_num = val.drop(labels=['reviewerID','itemID','nHelpful','pctHelpful'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare testidation dataset predicion dataframe\n",
    "X_test_pred = test.loc[:,['reviewerID','itemID','outOf']]\n",
    "\n",
    "# extract info\n",
    "y_test_outOf = test.loc[:,'outOf']\n",
    "\n",
    "# drop categorical columns\n",
    "X_test_num = test.drop(labels=['reviewerID','itemID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 15) (14000, 13)\n",
      "(160000, 2) (40000, 2) (14000, 2)\n",
      "(50529, 229) (12486, 229) (4400, 227)\n",
      "(50529, 225) (12486, 225) (4400, 225)\n",
      "(50529, 4) (12486, 4) (4400, 3)\n",
      "(50529,) (50529,) (50529,)\n",
      "(12486,) (12486,) (12486,)\n",
      "(4400,)\n"
     ]
    }
   ],
   "source": [
    "# check shapes\n",
    "print(orig_train_df.shape, orig_test_df.shape)\n",
    "print(X_train_sub_template.shape, X_val_sub_template.shape, X_test_sub_template.shape)\n",
    "\n",
    "print(train.shape, val.shape, test.shape)\n",
    "print(X_train_num.shape, X_val_num.shape, X_test_num.shape)\n",
    "print(X_train_pred.shape, X_val_pred.shape, X_test_pred.shape)\n",
    "print(y_train_pctHelpful.shape, y_train_nHelpful.shape, y_train_outOf.shape)\n",
    "print(y_val_pctHelpful.shape, y_val_nHelpful.shape, y_val_outOf.shape)\n",
    "print(y_test_outOf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ElasticNet regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.641198141919\n"
     ]
    }
   ],
   "source": [
    "best_err = 99\n",
    "best_a = 0.1\n",
    "for a in [0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,1.0]:\n",
    "    el = linear_model.ElasticNet(alpha=a, l1_ratio=0.01, fit_intercept=True)\n",
    "\n",
    "    el.fit(X_train_num, y_train_pctHelpful)\n",
    "\n",
    "    val_pred_pctHelpful = el.predict(X_val_num)\n",
    "\n",
    "    val_pred_pctHelpful[val_pred_pctHelpful < 0.0] = 0.0\n",
    "    val_pred_pctHelpful[val_pred_pctHelpful > 1.0] = 1.0\n",
    "\n",
    "    # convert predictions to nHelpful predictions\n",
    "    val_pred_nHelpful = val_pred_pctHelpful * y_val_outOf.values\n",
    "\n",
    "    # training errors\n",
    "    err = (mean_absolute_error(val_pred_nHelpful.round(0), y_val_nHelpful.values))\n",
    "    if err < best_err:\n",
    "        best_err = err\n",
    "        best_a = a\n",
    "\n",
    "print(best_a, best_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### split regression experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshwilson/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/joshwilson/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "best_mae = 99 #0.606599391318 #0.604629841852 # 0.604859041944\n",
    "best_thresh = 15 #23 #22\n",
    "\n",
    "for thresh in [15, 18, 19, 20, 21,22,23,24,25,26,27,28,29,35,40,50]:\n",
    "    y_val_pctHelpful = val.loc[:,'pctHelpful']\n",
    "    y_val_nHelpful = val.loc[:,'nHelpful']\n",
    "    y_val_outOf = val.loc[:,'outOf']\n",
    "    \n",
    "    # split data\n",
    "    train_1 = train.loc[train['outOf']<thresh,:]\n",
    "    train_2 = train.loc[train['outOf']>=thresh,:]\n",
    "    val_1 = val.loc[val['outOf']<thresh,:]\n",
    "    val_2 = val.loc[val['outOf']>=thresh,:]\n",
    "    \n",
    "    # extract info needed to evaluate mae\n",
    "    y_train_1_pctHelpful = train_1.loc[:,'pctHelpful']\n",
    "    y_train_1_nHelpful = train_1.loc[:,'nHelpful']\n",
    "    y_train_1_outOf = train_1.loc[:,'outOf']\n",
    "    y_train_2_pctHelpful = train_2.loc[:,'pctHelpful']\n",
    "    y_train_2_nHelpful = train_2.loc[:,'nHelpful']\n",
    "    y_train_2_outOf = train_2.loc[:,'outOf']\n",
    "\n",
    "    y_val_1_pctHelpful = val_1.loc[:,'pctHelpful']\n",
    "    y_val_1_nHelpful = val_1.loc[:,'nHelpful']\n",
    "    y_val_1_outOf = val_1.loc[:,'outOf']\n",
    "    y_val_2_pctHelpful = val_2.loc[:,'pctHelpful']\n",
    "    y_val_2_nHelpful = val_2.loc[:,'nHelpful']\n",
    "    y_val_2_outOf = val_2.loc[:,'outOf']\n",
    "\n",
    "    # drop categorical columns\n",
    "    X_train_num_1 = train_1.drop(labels=['reviewerID','itemID','nHelpful','pctHelpful'], axis=1)\n",
    "    X_train_num_2 = train_2.drop(labels=['reviewerID','itemID','nHelpful','pctHelpful'], axis=1)\n",
    "\n",
    "    X_val_num_1 = val_1.drop(labels=['reviewerID','itemID','nHelpful','pctHelpful'], axis=1)\n",
    "    X_val_num_2 = val_2.drop(labels=['reviewerID','itemID','nHelpful','pctHelpful'], axis=1)\n",
    "    \n",
    "    # regression models\n",
    "    el1 = linear_model.ElasticNet(alpha=best_a, l1_ratio=0.01, fit_intercept=True)\n",
    "    el1.fit(X_train_num_1, y_train_1_pctHelpful)\n",
    "    val_1_pred_pctHelpful = el1.predict(X_val_num_1)\n",
    "    val_1_pred_pctHelpful[val_1_pred_pctHelpful < 0.0] = 0.0\n",
    "    val_1_pred_pctHelpful[val_1_pred_pctHelpful > 1.0] = 1.0\n",
    "\n",
    "    el2 = linear_model.ElasticNet(alpha=best_a, l1_ratio=0.01, fit_intercept=True)\n",
    "    el2.fit(X_train_num_2, y_train_2_pctHelpful)\n",
    "    val_2_pred_pctHelpful = el1.predict(X_val_num_2)\n",
    "    val_2_pred_pctHelpful[val_2_pred_pctHelpful < 0.0] = 0.0\n",
    "    val_2_pred_pctHelpful[val_2_pred_pctHelpful > 1.0] = 1.0\n",
    "    \n",
    "    # convert predictions to nHelpful predictions\n",
    "    #train_pred_nHelpful = train_pred_pctHelpful * y_train_outOf.values\n",
    "    val_1_pred_nHelpful = val_1_pred_pctHelpful * y_val_1_outOf.values\n",
    "    val_2_pred_nHelpful = val_2_pred_pctHelpful * y_val_2_outOf.values\n",
    "    \n",
    "    # add predictions back to val_dfs\n",
    "    val_1['prediction'] = val_1_pred_nHelpful.round(0)\n",
    "    val_2['prediction'] = val_2_pred_nHelpful.round(0)\n",
    "    \n",
    "    # concatenate results\n",
    "    val_results = pd.concat([val_1, val_2])\n",
    "\n",
    "    # val errors\n",
    "    err = mean_absolute_error(val_results.prediction, val_results.nHelpful)\n",
    "    err1 = mean_absolute_error(val_1.prediction, val_1.nHelpful)\n",
    "    err2 = mean_absolute_error(val_2.prediction, val_2.nHelpful)\n",
    "    if err <= best_mae:\n",
    "        best_mae = err\n",
    "        best_thresh = thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 0.606679481019\n"
     ]
    }
   ],
   "source": [
    "print(best_thresh, best_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### regression model ablation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = best_thresh\n",
    "\n",
    "# split data according to best split of outOf\n",
    "y_val_pctHelpful = val.loc[:,'pctHelpful']\n",
    "y_val_nHelpful = val.loc[:,'nHelpful']\n",
    "y_val_outOf = val.loc[:,'outOf']\n",
    "\n",
    "# split data\n",
    "train_1 = train.loc[train['outOf']<thresh,:]\n",
    "train_2 = train.loc[train['outOf']>=thresh,:]\n",
    "val_1 = val.loc[val['outOf']<thresh,:]\n",
    "val_2 = val.loc[val['outOf']>=thresh,:]\n",
    "\n",
    "# extract info needed to evaluate mae\n",
    "y_train_1_pctHelpful = train_1.loc[:,'pctHelpful']\n",
    "y_train_1_nHelpful = train_1.loc[:,'nHelpful']\n",
    "y_train_1_outOf = train_1.loc[:,'outOf']\n",
    "y_train_2_pctHelpful = train_2.loc[:,'pctHelpful']\n",
    "y_train_2_nHelpful = train_2.loc[:,'nHelpful']\n",
    "y_train_2_outOf = train_2.loc[:,'outOf']\n",
    "\n",
    "y_val_1_pctHelpful = val_1.loc[:,'pctHelpful']\n",
    "y_val_1_nHelpful = val_1.loc[:,'nHelpful']\n",
    "y_val_1_outOf = val_1.loc[:,'outOf']\n",
    "y_val_2_pctHelpful = val_2.loc[:,'pctHelpful']\n",
    "y_val_2_nHelpful = val_2.loc[:,'nHelpful']\n",
    "y_val_2_outOf = val_2.loc[:,'outOf']\n",
    "\n",
    "# drop categorical columns\n",
    "X_train_num_1 = train_1.drop(labels=['reviewerID','itemID','nHelpful','pctHelpful'], axis=1)\n",
    "X_train_num_2 = train_2.drop(labels=['reviewerID','itemID','nHelpful','pctHelpful'], axis=1)\n",
    "\n",
    "X_val_num_1 = val_1.drop(labels=['reviewerID','itemID','nHelpful','pctHelpful'], axis=1)\n",
    "X_val_num_2 = val_2.drop(labels=['reviewerID','itemID','nHelpful','pctHelpful'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n"
     ]
    }
   ],
   "source": [
    "# get list of features in our dataset\n",
    "features = X_train_num.columns.values\n",
    "\n",
    "# change below to run on different subsets of data split by 'outOf'\n",
    "X_train_temp = X_train_num_1\n",
    "X_val_temp = X_val_num_1\n",
    "\n",
    "y_train_pctHelpful = y_train_1_pctHelpful\n",
    "y_val_pctHelpful = y_val_1_pctHelpful\n",
    "y_val_nHelpful = y_val_1_nHelpful\n",
    "y_val_outOf = y_val_1_outOf\n",
    "\n",
    "cur_best_mae = 100.0\n",
    "removed_features_list_1 = []\n",
    "best_maes = []\n",
    "\n",
    "for i in range(len(features)):\n",
    "    print(i)\n",
    "    mae = []\n",
    "    \n",
    "    feat = X_train_temp.columns.values\n",
    "    for f in feat:\n",
    "        X_train_abl = X_train_temp.drop(labels=[f],axis=1)\n",
    "        X_val_abl = X_val_temp.drop(labels=[f],axis=1)\n",
    "        \n",
    "        # build regression model without feature\n",
    "        el1 = linear_model.ElasticNet(alpha=best_a, l1_ratio=0.01, fit_intercept=True)\n",
    "        el1.fit(X_train_abl, y_train_pctHelpful)\n",
    "        val_pred_pctHelpful = el1.predict(X_val_abl)\n",
    "        val_pred_pctHelpful[val_pred_pctHelpful < 0.0] = 0.0\n",
    "        val_pred_pctHelpful[val_pred_pctHelpful > 1.0] = 1.0\n",
    "\n",
    "        # convert predictions to nHelpful predictions\n",
    "        val_pred_nHelpful = val_pred_pctHelpful * y_val_outOf.values\n",
    "        \n",
    "        # val errors\n",
    "        mae.append(mean_absolute_error(val_pred_nHelpful.round(0), y_val_nHelpful.values))\n",
    "\n",
    "    # find best feature to remove\n",
    "    min_mae = np.min(np.array(mae))\n",
    "    min_mae_feat = feat[np.where(mae == min_mae)[0]][0]\n",
    "    \n",
    "    # if removing feature improves current best error\n",
    "    if min_mae <= cur_best_mae:\n",
    "        # update current best error\n",
    "        cur_best_mae = min_mae\n",
    "        best_maes.append(min_mae)\n",
    "        \n",
    "        # add feature to removed features list\n",
    "        removed_features_list_1.append(min_mae_feat)\n",
    "        \n",
    "        # update X_train_temp and X_val_temp by dropping feature\n",
    "        X_train_temp = X_train_temp.drop(labels=[min_mae_feat],axis=1)\n",
    "        X_val_temp = X_val_temp.drop(labels=[min_mae_feat],axis=1)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.489175342919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['avgUserHelpfulness',\n",
       " 'itemRatedReviews',\n",
       " 'category_Men',\n",
       " 'reviewTextNumWords',\n",
       " 'unixReviewTime',\n",
       " 'category_Plus-Size',\n",
       " 'category_Athletic',\n",
       " 'pctUserReviewsRated',\n",
       " 'pctItemReviewsRated',\n",
       " 'numCategories',\n",
       " 'category_Clothing, Shoes & Jewelry',\n",
       " 'category_Clothing',\n",
       " 'category_Shoes',\n",
       " 'category_Shoes & Accessories: International Shipping Available',\n",
       " 'category_Novelty, Costumes & More',\n",
       " 'category_Novelty',\n",
       " 'category_Lingerie, Sleep & Lounge',\n",
       " 'category_Jewelry',\n",
       " 'category_Intimates',\n",
       " 'category_Accessories',\n",
       " 'category_Sports & Outdoors',\n",
       " 'category_Comfort Shoes',\n",
       " 'category_Tops & Tees',\n",
       " 'category_Active',\n",
       " 'category_Bras',\n",
       " 'category_Jewelry: International Shipping Available',\n",
       " 'category_Sandals',\n",
       " 'category_C',\n",
       " 'category_Big & Tall',\n",
       " 'category_Boots',\n",
       " 'category_Dresses',\n",
       " 'category_Everyday Bras',\n",
       " 'category_Casual',\n",
       " 'category_Watches',\n",
       " 'category_Wrist Watches',\n",
       " 'category_Fashion',\n",
       " 'category_Boot Shop',\n",
       " 'category_Earrings',\n",
       " 'category_Blouses & Button-Down Shirts',\n",
       " 'category_New Arrivals',\n",
       " 'category_S',\n",
       " 'category_Shirts',\n",
       " 'category_Fine',\n",
       " 'category_Amazon Curated Collection',\n",
       " 'category_Running',\n",
       " 'category_Pants',\n",
       " 'category_N',\n",
       " 'category_Jeans',\n",
       " 'category_D',\n",
       " 'category_Handbags & Wallets',\n",
       " 'category_Available for International Shipping',\n",
       " 'category_Panties',\n",
       " 'category_Underwear',\n",
       " 'category_Flats',\n",
       " 'category_Socks',\n",
       " 'category_Exotic Apparel',\n",
       " 'category_Sleep & Lounge',\n",
       " 'category_T-Shirts',\n",
       " 'category_Leggings',\n",
       " 'category_Band & Music Fan',\n",
       " 'category_Necklaces & Pendants',\n",
       " 'category_Loafers & Slip-Ons',\n",
       " 'category_Fashion Watches',\n",
       " 'category_Clarks',\n",
       " 'category_Rings',\n",
       " 'category_Socks & Hosiery',\n",
       " 'category_Pumps',\n",
       " 'category_Hats & Caps',\n",
       " 'category_Fashion Sneakers',\n",
       " 'category_Skechers',\n",
       " 'category_B',\n",
       " 'category_Night Out & Cocktail',\n",
       " 'category_M',\n",
       " 'category_Sweaters',\n",
       " 'category_Slippers',\n",
       " 'category_Outdoor',\n",
       " 'category_Work Wear & Uniforms',\n",
       " 'category_Active Pants',\n",
       " 'category_Knits & Tees',\n",
       " 'category_R',\n",
       " 'category_T',\n",
       " 'category_Winter Promo',\n",
       " 'category_Shapewear',\n",
       " 'category_Briefs',\n",
       " 'category_New Balance',\n",
       " 'category_Baby',\n",
       " 'category_Sport Watches',\n",
       " 'category_Necklaces',\n",
       " 'category_Mules & Clogs',\n",
       " 'category_crocs',\n",
       " 'category_Shorts',\n",
       " 'category_Outdoor & Work',\n",
       " 'category_Skirts',\n",
       " 'category_K',\n",
       " 'category_Scarves & Wraps',\n",
       " 'category_Top-Handle Bags',\n",
       " 'category_Gemstones',\n",
       " 'category_Juniors',\n",
       " 'category_Girls',\n",
       " 'category_Athletic Socks',\n",
       " 'category_Shoulder Bags',\n",
       " 'category_Active Shirts & Tees',\n",
       " 'category_Wallets, Card Cases & Money Organizers',\n",
       " 'category_Walking',\n",
       " 'category_Belts',\n",
       " 'category_Bracelets',\n",
       " 'category_F',\n",
       " 'category_ASICS',\n",
       " 'category_Tanks & Camis',\n",
       " 'category_Street, Surf & Skate',\n",
       " 'category_Invicta',\n",
       " 'category_Wallets',\n",
       " 'category_Baby Girls',\n",
       " 'category_Sunglasses & Eyewear Accessories',\n",
       " 'category_Sports Bras',\n",
       " 'category_Jackets & Coats',\n",
       " 'category_Sunglasses',\n",
       " 'category_Casual Socks',\n",
       " 'category_Baby Boys',\n",
       " 'category_Pendants',\n",
       " 'category_New Jewelry',\n",
       " 'category_L',\n",
       " 'category_Fashion Scarves',\n",
       " 'category_Coats & Jackets',\n",
       " 'category_Exercise & Fitness',\n",
       " \"category_Men's Athletic Watches\",\n",
       " 'category_Boys',\n",
       " 'category_Tunics',\n",
       " 'category_Surf, Skate & Street',\n",
       " 'category_Wedding & Engagement Rings',\n",
       " 'category_Blouses',\n",
       " 'category_E',\n",
       " 'category_Cardigans',\n",
       " 'category_Drop & Dangle',\n",
       " 'category_Carhartt',\n",
       " 'category_Swimsuits & Cover Ups',\n",
       " 'category_Dickies',\n",
       " 'category_Merrell',\n",
       " 'category_Active Shorts',\n",
       " 'category_Jewelry Outlet',\n",
       " 'category_Keen',\n",
       " 'category_Stud',\n",
       " 'category_Hiking & Trekking',\n",
       " 'category_Bikinis',\n",
       " 'category_Special Occasion',\n",
       " 'category_Dockers',\n",
       " 'category_Pullovers',\n",
       " 'category_Robes',\n",
       " 'category_Boxer Briefs',\n",
       " 'category_FitFlop',\n",
       " 'category_Dress',\n",
       " 'category_Maternity',\n",
       " 'category_Test Women AAQ',\n",
       " 'category_Swim',\n",
       " 'category_Teva',\n",
       " 'category_Gloves & Mittens',\n",
       " 'category_Oxfords',\n",
       " 'category_Shearling',\n",
       " 'category_Sport Sandals',\n",
       " \"category_Women's Luxury Brands\",\n",
       " 'category_Timex',\n",
       " 'category_Columbia',\n",
       " 'category_Plain Silver Jewelry',\n",
       " 'category_Nine West',\n",
       " 'category_Bodysuits',\n",
       " 'category_Fitness & Cross-Training',\n",
       " 'category_J',\n",
       " 'category_Wear to Work',\n",
       " 'category_Snow & Cold Weather',\n",
       " 'category_Cold Weather Gloves',\n",
       " 'category_Work Utility & Safety',\n",
       " 'category_Tops',\n",
       " 'category_Hosiery',\n",
       " 'category_Calvin Klein',\n",
       " 'category_Naturalizer',\n",
       " 'category_Wedding Rings',\n",
       " 'category_Pearl Jewelry',\n",
       " 'category_Sets',\n",
       " 'category_Wraps & Pashminas',\n",
       " 'category_Hoodies',\n",
       " 'category_Bustiers & Corsets',\n",
       " 'category_Nightgowns & Sleepshirts',\n",
       " 'category_Rain Footwear',\n",
       " 'category_P',\n",
       " 'category_Thermal Underwear',\n",
       " 'category_Timex test',\n",
       " 'category_Pants & Capris',\n",
       " 'category_Trail Running',\n",
       " 'category_Yoga',\n",
       " 'category_Casual Button-Down Shirts',\n",
       " 'category_Costumes & Accessories',\n",
       " 'category_Aerosoles',\n",
       " 'category_Snow Boots',\n",
       " 'category_H',\n",
       " 'category_Undershirts',\n",
       " 'category_Active Leggings',\n",
       " 'category_Watch Accessories',\n",
       " 'category_Dress Shirts',\n",
       " 'category_Bella',\n",
       " 'category_Polos',\n",
       " 'category_Tights',\n",
       " 'category_Fashion Hoodies & Sweatshirts',\n",
       " 'category_Dansko',\n",
       " 'category_Tights & Leggings',\n",
       " 'category_Reebok',\n",
       " 'summaryTextNumWords',\n",
       " 'reviewTextPctWordsAllCaps',\n",
       " 'summaryTextPctWordsAllCaps',\n",
       " 'reviewTextPctSentsAllCaps',\n",
       " 'reviewTxtPctCapsLetters',\n",
       " 'summaryTxtPctCapsLetters',\n",
       " 'reviewTxtPctPunct',\n",
       " 'summaryTxtPctPunct']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write removed features to csv file for reading in later\n",
    "rf1 = pd.DataFrame(removed_features_list_1)\n",
    "rf1.to_csv('removed_features_list_1.csv')\n",
    "\n",
    "print(cur_best_mae)\n",
    "removed_features_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n"
     ]
    }
   ],
   "source": [
    "# get list of features in our dataset\n",
    "features = X_train_num.columns.values\n",
    "\n",
    "# change below to run on different subsets of data split by 'outOf'\n",
    "X_train_temp = X_train_num_2\n",
    "X_val_temp = X_val_num_2\n",
    "\n",
    "y_train_pctHelpful = y_train_2_pctHelpful\n",
    "y_val_pctHelpful = y_val_2_pctHelpful\n",
    "y_val_nHelpful = y_val_2_nHelpful\n",
    "y_val_outOf = y_val_2_outOf\n",
    "\n",
    "cur_best_mae = 100.0\n",
    "removed_features_list_2 = []\n",
    "best_maes = []\n",
    "\n",
    "for i in range(len(features)):\n",
    "    print(i)\n",
    "    mae = []\n",
    "    \n",
    "    feat = X_train_temp.columns.values\n",
    "    for f in feat:\n",
    "        X_train_abl = X_train_temp.drop(labels=[f],axis=1)\n",
    "        X_val_abl = X_val_temp.drop(labels=[f],axis=1)\n",
    "        \n",
    "        # build regression model without feature\n",
    "        el1 = linear_model.ElasticNet(alpha=best_a, l1_ratio=0.01, fit_intercept=True)\n",
    "        el1.fit(X_train_abl, y_train_pctHelpful)\n",
    "        val_pred_pctHelpful = el1.predict(X_val_abl)\n",
    "        val_pred_pctHelpful[val_pred_pctHelpful < 0.0] = 0.0\n",
    "        val_pred_pctHelpful[val_pred_pctHelpful > 1.0] = 1.0\n",
    "\n",
    "        # convert predictions to nHelpful predictions\n",
    "        val_pred_nHelpful = val_pred_pctHelpful * y_val_outOf.values\n",
    "        \n",
    "        # val errors\n",
    "        mae.append(mean_absolute_error(val_pred_nHelpful.round(0), y_val_nHelpful.values))\n",
    "\n",
    "    # find best feature to remove\n",
    "    min_mae = np.min(np.array(mae))\n",
    "    min_mae_feat = feat[np.where(mae == min_mae)[0]][0]\n",
    "    \n",
    "    # if removing feature improves current best error\n",
    "    if min_mae <= cur_best_mae:\n",
    "        # update current best error\n",
    "        cur_best_mae = min_mae\n",
    "        best_maes.append(min_mae)\n",
    "        \n",
    "        # add feature to removed features list\n",
    "        removed_features_list_2.append(min_mae_feat)\n",
    "        \n",
    "        # update X_train_temp and X_val_temp by dropping feature\n",
    "        X_train_temp = X_train_temp.drop(labels=[min_mae_feat],axis=1)\n",
    "        X_val_temp = X_val_temp.drop(labels=[min_mae_feat],axis=1)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3515625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['reviewTextFKscore',\n",
       " 'reviewTextFscore',\n",
       " 'avgItemHelpfulness',\n",
       " 'reviewTextNumSents',\n",
       " 'reviewTextNumWords',\n",
       " 'category_Men',\n",
       " 'userTotReviews',\n",
       " 'userRatedReviews',\n",
       " 'pctUserReviewsRated',\n",
       " 'pctItemReviewsRated',\n",
       " 'numCategories',\n",
       " 'category_Clothing, Shoes & Jewelry',\n",
       " 'category_Clothing',\n",
       " 'category_Shoes',\n",
       " 'category_Shoes & Accessories: International Shipping Available',\n",
       " 'category_Novelty, Costumes & More',\n",
       " 'category_Novelty',\n",
       " 'category_Petite',\n",
       " 'category_Lingerie, Sleep & Lounge',\n",
       " 'category_Jewelry',\n",
       " 'category_Intimates',\n",
       " 'category_Accessories',\n",
       " 'category_Sports & Outdoors',\n",
       " 'category_Comfort Shoes',\n",
       " 'category_Tops & Tees',\n",
       " 'category_Plus-Size',\n",
       " 'category_Active',\n",
       " 'category_Athletic',\n",
       " 'category_Bras',\n",
       " 'category_Jewelry: International Shipping Available',\n",
       " 'category_Sandals',\n",
       " 'category_C',\n",
       " 'category_Big & Tall',\n",
       " 'category_Boots',\n",
       " 'category_Dresses',\n",
       " 'category_Everyday Bras',\n",
       " 'category_Casual',\n",
       " 'category_Watches',\n",
       " 'category_Wrist Watches',\n",
       " 'category_Fashion',\n",
       " 'category_Boot Shop',\n",
       " 'category_Earrings',\n",
       " 'category_Blouses & Button-Down Shirts',\n",
       " 'category_New Arrivals',\n",
       " 'category_S',\n",
       " 'category_Shirts',\n",
       " 'category_Fine',\n",
       " 'category_Amazon Curated Collection',\n",
       " 'category_Running',\n",
       " 'category_Pants',\n",
       " 'category_N',\n",
       " 'category_Jeans',\n",
       " 'category_D',\n",
       " 'category_Handbags & Wallets',\n",
       " 'category_Available for International Shipping',\n",
       " 'category_Panties',\n",
       " 'category_Underwear',\n",
       " 'category_Flats',\n",
       " 'category_Socks',\n",
       " 'category_Exotic Apparel',\n",
       " 'category_Sleep & Lounge',\n",
       " 'category_T-Shirts',\n",
       " 'category_Leggings',\n",
       " 'category_Band & Music Fan',\n",
       " 'category_Necklaces & Pendants',\n",
       " 'category_Loafers & Slip-Ons',\n",
       " 'category_Fashion Watches',\n",
       " 'category_Clarks',\n",
       " 'category_Rings',\n",
       " 'category_Socks & Hosiery',\n",
       " 'category_Pumps',\n",
       " 'category_Hats & Caps',\n",
       " 'category_Fashion Sneakers',\n",
       " 'category_Skechers',\n",
       " 'category_B',\n",
       " 'category_Night Out & Cocktail',\n",
       " 'category_M',\n",
       " 'category_Sweaters',\n",
       " 'category_Slippers',\n",
       " 'category_Outdoor',\n",
       " 'category_Work Wear & Uniforms',\n",
       " 'category_Active Pants',\n",
       " 'category_Knits & Tees',\n",
       " 'category_R',\n",
       " 'category_T',\n",
       " 'category_Winter Promo',\n",
       " 'category_Shapewear',\n",
       " 'category_Briefs',\n",
       " 'category_New Balance',\n",
       " 'category_Baby',\n",
       " 'category_Sport Watches',\n",
       " 'category_Necklaces',\n",
       " 'category_Mules & Clogs',\n",
       " 'category_crocs',\n",
       " 'category_Shorts',\n",
       " 'category_Outdoor & Work',\n",
       " 'category_Skirts',\n",
       " 'category_K',\n",
       " 'category_Scarves & Wraps',\n",
       " 'category_Top-Handle Bags',\n",
       " 'category_Gemstones',\n",
       " 'category_Juniors',\n",
       " 'category_Girls',\n",
       " 'category_Athletic Socks',\n",
       " 'category_Shoulder Bags',\n",
       " 'category_Active Shirts & Tees',\n",
       " 'category_Wallets, Card Cases & Money Organizers',\n",
       " 'category_Walking',\n",
       " 'category_Belts',\n",
       " 'category_Bracelets',\n",
       " 'category_F',\n",
       " 'category_ASICS',\n",
       " 'category_Tanks & Camis',\n",
       " 'category_Street, Surf & Skate',\n",
       " 'category_Invicta',\n",
       " 'category_Wallets',\n",
       " 'category_Baby Girls',\n",
       " 'category_Sunglasses & Eyewear Accessories',\n",
       " 'category_Sports Bras',\n",
       " 'category_Jackets & Coats',\n",
       " 'category_Sunglasses',\n",
       " 'category_Casual Socks',\n",
       " 'category_Baby Boys',\n",
       " 'category_Pendants',\n",
       " 'category_New Jewelry',\n",
       " 'category_L',\n",
       " 'category_Fashion Scarves',\n",
       " 'category_Coats & Jackets',\n",
       " 'category_Exercise & Fitness',\n",
       " \"category_Men's Athletic Watches\",\n",
       " 'category_Boys',\n",
       " 'category_Tunics',\n",
       " 'category_Surf, Skate & Street',\n",
       " 'category_Wedding & Engagement Rings',\n",
       " 'category_Blouses',\n",
       " 'category_E',\n",
       " 'category_Cardigans',\n",
       " 'category_Drop & Dangle',\n",
       " 'category_Carhartt',\n",
       " 'category_Swimsuits & Cover Ups',\n",
       " 'category_Dickies',\n",
       " 'category_Merrell',\n",
       " 'category_Active Shorts',\n",
       " 'category_Jewelry Outlet',\n",
       " 'category_Keen',\n",
       " 'category_Stud',\n",
       " 'category_Hiking & Trekking',\n",
       " 'category_Bikinis',\n",
       " 'category_Special Occasion',\n",
       " 'category_Dockers',\n",
       " 'category_Pullovers',\n",
       " 'category_Robes',\n",
       " 'category_Boxer Briefs',\n",
       " 'category_FitFlop',\n",
       " 'category_Dress',\n",
       " 'category_Maternity',\n",
       " 'category_Test Women AAQ',\n",
       " 'category_Swim',\n",
       " 'category_Teva',\n",
       " 'category_Gloves & Mittens',\n",
       " 'category_Oxfords',\n",
       " 'category_Shearling',\n",
       " 'category_Sport Sandals',\n",
       " \"category_Women's Luxury Brands\",\n",
       " 'category_Timex',\n",
       " 'category_Columbia',\n",
       " 'category_Plain Silver Jewelry',\n",
       " 'category_Nine West',\n",
       " 'category_Bodysuits',\n",
       " 'category_Fitness & Cross-Training',\n",
       " 'category_J',\n",
       " 'category_Wear to Work',\n",
       " 'category_Snow & Cold Weather',\n",
       " 'category_Cold Weather Gloves',\n",
       " 'category_Work Utility & Safety',\n",
       " 'category_Tops',\n",
       " 'category_Hosiery',\n",
       " 'category_Calvin Klein',\n",
       " 'category_Naturalizer',\n",
       " 'category_Wedding Rings',\n",
       " 'category_Pearl Jewelry',\n",
       " 'category_Sets',\n",
       " 'category_Wraps & Pashminas',\n",
       " 'category_Hoodies',\n",
       " 'category_Bustiers & Corsets',\n",
       " 'category_Nightgowns & Sleepshirts',\n",
       " 'category_Rain Footwear',\n",
       " 'category_P',\n",
       " 'category_Thermal Underwear',\n",
       " 'category_Timex test',\n",
       " 'category_Pants & Capris',\n",
       " 'category_Trail Running',\n",
       " 'category_Yoga',\n",
       " 'category_Casual Button-Down Shirts',\n",
       " 'category_Costumes & Accessories',\n",
       " 'category_Aerosoles',\n",
       " 'category_Snow Boots',\n",
       " 'category_H',\n",
       " 'category_Undershirts',\n",
       " 'category_Active Leggings',\n",
       " 'category_Watch Accessories',\n",
       " 'category_Dress Shirts',\n",
       " 'category_Bella',\n",
       " 'category_Polos',\n",
       " 'category_Tights',\n",
       " 'category_Fashion Hoodies & Sweatshirts',\n",
       " 'category_Dansko',\n",
       " 'category_Tights & Leggings',\n",
       " 'category_Reebok',\n",
       " 'reviewTextPctWordsAllCaps',\n",
       " 'summaryTextPctWordsAllCaps',\n",
       " 'reviewTextPctSentsAllCaps',\n",
       " 'reviewTxtPctCapsLetters',\n",
       " 'summaryTxtPctCapsLetters',\n",
       " 'reviewTxtPctPunct',\n",
       " 'summaryTxtPctPunct']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write list to csv\n",
    "rf2 = pd.DataFrame(removed_features_list_2)\n",
    "rf2.to_csv('removed_features_list_2.csv')\n",
    "\n",
    "print(cur_best_mae)\n",
    "removed_features_list_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### create split regression model after removing ablated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "removed_feat_1 = removed_features_list_1\n",
    "removed_feat_2 = removed_features_list_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Regression model for split data with removed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshwilson/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:21: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 0; dimension is 12102 but corresponding boolean dimension is 384\n",
      "/Users/joshwilson/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:22: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 0; dimension is 12102 but corresponding boolean dimension is 384\n"
     ]
    }
   ],
   "source": [
    "# remove ablated features from each split of data\n",
    "X_train_abl_1 = train_1.drop(labels=removed_feat_1, axis=1)\n",
    "X_val_abl_1 = val_1.drop(labels=removed_feat_1, axis=1)\n",
    "X_train_abl_2 = train_2.drop(labels=removed_feat_2, axis=1)\n",
    "X_val_abl_2 = val_2.drop(labels=removed_feat_2, axis=1)\n",
    "\n",
    "# drop categorical inputs\n",
    "X_train_abl_1_num = X_train_abl_1.drop(labels=['itemID','reviewerID','nHelpful','pctHelpful'], axis=1)\n",
    "X_train_abl_2_num = X_train_abl_2.drop(labels=['itemID','reviewerID','nHelpful','pctHelpful'], axis=1)\n",
    "X_val_abl_1_num = X_val_abl_1.drop(labels=['itemID','reviewerID','nHelpful','pctHelpful'], axis=1)\n",
    "X_val_abl_2_num = X_val_abl_2.drop(labels=['itemID','reviewerID','nHelpful','pctHelpful'], axis=1)\n",
    "\n",
    "# fit elasticnet model\n",
    "el1 = linear_model.ElasticNet(alpha=best_a, l1_ratio=0.01, fit_intercept=True)\n",
    "el2 = linear_model.ElasticNet(alpha=best_a, l1_ratio=0.01, fit_intercept=True)\n",
    "\n",
    "el1.fit(X_train_abl_1_num, y_train_1_pctHelpful)\n",
    "el2.fit(X_train_abl_2_num, y_train_2_pctHelpful)\n",
    "\n",
    "val_1_pred_pctHelpful = el1.predict(X_val_abl_1_num)\n",
    "val_1_pred_pctHelpful[val_pred_pctHelpful < 0.0] = 0.0\n",
    "val_1_pred_pctHelpful[val_pred_pctHelpful > 1.0] = 1.0\n",
    "\n",
    "val_2_pred_pctHelpful = el2.predict(X_val_abl_2_num)\n",
    "val_2_pred_pctHelpful[val_pred_pctHelpful < 0.0] = 0.0\n",
    "val_2_pred_pctHelpful[val_pred_pctHelpful > 1.0] = 1.0\n",
    "\n",
    "# convert predictions to nHelpful predictions\n",
    "val_1_pred_nHelpful = val_1_pred_pctHelpful * y_val_1_outOf.values\n",
    "val_2_pred_nHelpful = val_2_pred_pctHelpful * y_val_2_outOf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12486, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_1_pred = val_1.loc[:,['reviewerID','itemID','outOf','nHelpful']]\n",
    "val_1_pred['prediction'] = val_1_pred_nHelpful\n",
    "\n",
    "val_2_pred = val_2.loc[:,['reviewerID','itemID','outOf','nHelpful']]\n",
    "val_2_pred['prediction'] = val_2_pred_nHelpful\n",
    "\n",
    "val_pred = pd.concat([val_1_pred, val_2_pred])\n",
    "\n",
    "val_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_val_submission = pd.merge(X_val_sub_template, val_pred, how='left', on=['reviewerID','itemID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>outOf</th>\n",
       "      <th>nHelpful</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U232545388</td>\n",
       "      <td>I919490106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.770983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U629278857</td>\n",
       "      <td>I317532014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U772466163</td>\n",
       "      <td>I022571677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U649013417</td>\n",
       "      <td>I313758331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U709855261</td>\n",
       "      <td>I128829618</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.834080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewerID      itemID  outOf  nHelpful  prediction\n",
       "0  U232545388  I919490106    1.0       1.0    0.770983\n",
       "1  U629278857  I317532014    NaN       NaN         NaN\n",
       "2  U772466163  I022571677    NaN       NaN         NaN\n",
       "3  U649013417  I313758331    NaN       NaN         NaN\n",
       "4  U709855261  I128829618    1.0       1.0    0.834080"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val_submission.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.204213157693\n",
      "0.1807\n"
     ]
    }
   ],
   "source": [
    "print (mean_absolute_error(X_val_submission.nHelpful.values, X_val_submission.prediction.values))\n",
    "print (mean_absolute_error(X_val_submission.nHelpful.values, X_val_submission.prediction.values.round(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### train regression model using combined training + validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "outlier_train_idx_t1 = train_1.loc[(train_1.outOf > 80) & (train_1.pctHelpful < 0.2),:].index.values\n",
    "train_1 = train_1.drop(outlier_train_idx_t1)\n",
    "outlier_train_idx_t2 = train_2.loc[(train_2.outOf > 80) & (train_2.pctHelpful < 0.2),:].index.values\n",
    "train_2 = train_2.drop(outlier_train_idx_t2)\n",
    "\n",
    "outlier_val_idx_v1 = val_1.loc[(val_1.outOf > 80) & (val_1.pctHelpful < 0.2),:].index.values\n",
    "val_1 = val_1.drop(outlier_val_idx_v1)\n",
    "outlier_val_idx_v2 = val_2.loc[(val_2.outOf > 80) & (val_2.pctHelpful < 0.2),:].index.values\n",
    "val_2 = val_2.drop(outlier_val_idx_v2)\n",
    "\n",
    "# extract info needed for prediction\n",
    "y_train_1_pctHelpful = train_1.loc[:,'pctHelpful']\n",
    "y_train_1_nHelpful = train_1.loc[:,'nHelpful']\n",
    "y_train_1_outOf = train_1.loc[:,'outOf']\n",
    "y_train_2_pctHelpful = train_2.loc[:,'pctHelpful']\n",
    "y_train_2_nHelpful = train_2.loc[:,'nHelpful']\n",
    "y_train_2_outOf = train_2.loc[:,'outOf']\n",
    "\n",
    "y_val_1_pctHelpful = val_1.loc[:,'pctHelpful']\n",
    "y_val_1_nHelpful = val_1.loc[:,'nHelpful']\n",
    "y_val_1_outOf = val_1.loc[:,'outOf']\n",
    "y_val_2_pctHelpful = val_2.loc[:,'pctHelpful']\n",
    "y_val_2_nHelpful = val_2.loc[:,'nHelpful']\n",
    "y_val_2_outOf = val_2.loc[:,'outOf']\n",
    "\n",
    "# remove ablated features from each split of data\n",
    "X_train_abl_1 = train_1.drop(labels=removed_feat_1, axis=1)\n",
    "X_val_abl_1 = val_1.drop(labels=removed_feat_1, axis=1)\n",
    "X_train_abl_2 = train_2.drop(labels=removed_feat_2, axis=1)\n",
    "X_val_abl_2 = val_2.drop(labels=removed_feat_2, axis=1)\n",
    "\n",
    "# train model using all data\n",
    "X_both_1 = pd.concat([X_train_abl_1, X_val_abl_1])\n",
    "X_both_2 = pd.concat([X_train_abl_2, X_val_abl_2])\n",
    "\n",
    "y_both_1_pctHelpful = np.concatenate((y_train_1_pctHelpful,y_val_1_pctHelpful))\n",
    "y_both_2_pctHelpful = np.concatenate((y_train_2_pctHelpful,y_val_2_pctHelpful))\n",
    "\n",
    "# drop categorical features\n",
    "X_both_1_num = X_both_1.drop(labels=['itemID','reviewerID','nHelpful','pctHelpful'], axis=1)\n",
    "X_both_2_num = X_both_2.drop(labels=['itemID','reviewerID','nHelpful','pctHelpful'], axis=1)\n",
    "\n",
    "# fit elasticnet model\n",
    "el1 = linear_model.ElasticNet(alpha=best_a, l1_ratio=0.01, fit_intercept=True)\n",
    "el2 = linear_model.ElasticNet(alpha=best_a, l1_ratio=0.01, fit_intercept=True)\n",
    "\n",
    "el1.fit(X_both_1_num, y_both_1_pctHelpful)\n",
    "el2.fit(X_both_2_num, y_both_2_pctHelpful)\n",
    "\n",
    "# split test data\n",
    "test_1 = test.loc[test['outOf']<thresh,:]\n",
    "test_2 = test.loc[test['outOf']>=thresh,:]\n",
    "\n",
    "# extract data needed for prediction\n",
    "y_test_1_outOf = test_1.loc[:,'outOf']\n",
    "y_test_2_outOf = test_2.loc[:,'outOf']\n",
    "\n",
    "# remove ablated features\n",
    "test_1 = test_1.drop(labels=removed_feat_1, axis=1)\n",
    "test_2 = test_2.drop(labels=removed_feat_2, axis=1)\n",
    "\n",
    "# drop categorical columns\n",
    "X_test_num_1 = test_1.drop(labels=['reviewerID','itemID'], axis=1)\n",
    "X_test_num_2 = test_2.drop(labels=['reviewerID','itemID'], axis=1)\n",
    "\n",
    "# make predictions on test data\n",
    "test_1_pred_pctHelpful = el1.predict(X_test_num_1)\n",
    "test_1_pred_pctHelpful[test_1_pred_pctHelpful < 0.0] = 0.0\n",
    "test_1_pred_pctHelpful[test_1_pred_pctHelpful > 1.0] = 1.0\n",
    "\n",
    "test_2_pred_pctHelpful = el2.predict(X_test_num_2)\n",
    "test_2_pred_pctHelpful[test_2_pred_pctHelpful < 0.0] = 0.0\n",
    "test_2_pred_pctHelpful[test_2_pred_pctHelpful > 1.0] = 1.0\n",
    "\n",
    "# convert predictions to nHelpful predictions\n",
    "test_1_pred_nHelpful = test_1_pred_pctHelpful * y_test_1_outOf.values\n",
    "test_2_pred_nHelpful = test_2_pred_pctHelpful * y_test_2_outOf.values\n",
    "\n",
    "test_1_pred = test_1.loc[:,['reviewerID','itemID','outOf']]\n",
    "test_1_pred['prediction'] = test_1_pred_nHelpful.round(0)\n",
    "\n",
    "test_2_pred = test_2.loc[:,['reviewerID','itemID','outOf']]\n",
    "test_2_pred['prediction'] = test_2_pred_nHelpful.round(0)\n",
    "\n",
    "X_test_pred = pd.concat([test_1_pred, test_2_pred])\n",
    "\n",
    "X_test_reg_submission_el = pd.merge(X_test_sub_template, X_test_pred, how='left', on=['reviewerID','itemID'])\n",
    "X_test_reg_submission_el.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write elasticnet regression results to file\n",
    "predictions = open(\"predictions_Helpful_el0611.txt\", 'w')\n",
    "for l in open(\"pairs_Helpful.txt\"):\n",
    "  if l.startswith(\"userID\"):\n",
    "    #header\n",
    "    predictions.write(l)\n",
    "    continue\n",
    "  u,i,outOf = l.strip().split('-')\n",
    "  outOf = int(outOf)\n",
    "  \n",
    "  pred = X_test_reg_submission_el.loc[(X_test_reg_submission_el['reviewerID']==u) &\n",
    "                                  (X_test_reg_submission_el['itemID']==i)].prediction.values[0]\n",
    "  predictions.write(u + '-' + i + '-' + str(outOf) + ',' + str(pred) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49046, 12) (1483, 9) (50529, 225)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_abl_1_num.shape, X_train_abl_2_num.shape, X_train_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>price</th>\n",
       "      <th>outOf</th>\n",
       "      <th>nHelpful</th>\n",
       "      <th>pctHelpful</th>\n",
       "      <th>userTotReviews</th>\n",
       "      <th>itemTotReviews</th>\n",
       "      <th>avgItemHelpfulness</th>\n",
       "      <th>userRatedReviews</th>\n",
       "      <th>category_Women</th>\n",
       "      <th>category_Petite</th>\n",
       "      <th>reviewTextNumSents</th>\n",
       "      <th>reviewTextFscore</th>\n",
       "      <th>reviewTextFKscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I500768895</td>\n",
       "      <td>U021132998</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>76.005682</td>\n",
       "      <td>6.757121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I243311479</td>\n",
       "      <td>U482369528</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>70.630000</td>\n",
       "      <td>4.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I496891609</td>\n",
       "      <td>U737837172</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.99</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.434643</td>\n",
       "      <td>3.114524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I725702722</td>\n",
       "      <td>U866103305</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>84.032353</td>\n",
       "      <td>4.555126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I716842709</td>\n",
       "      <td>U701505038</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>83.598333</td>\n",
       "      <td>6.070741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       itemID  reviewerID  rating  price  outOf  nHelpful  pctHelpful  \\\n",
       "0  I500768895  U021132998     4.0  -1.00      4         4         1.0   \n",
       "1  I243311479  U482369528     4.0   9.99      2         2         1.0   \n",
       "2  I496891609  U737837172     5.0  19.99      7         7         1.0   \n",
       "3  I725702722  U866103305     5.0  -1.00      2         1         0.5   \n",
       "4  I716842709  U701505038     5.0  10.00      1         1         1.0   \n",
       "\n",
       "   userTotReviews  itemTotReviews  avgItemHelpfulness  userRatedReviews  \\\n",
       "0              17              13            0.800000                 9   \n",
       "1               3               7            1.000000                 2   \n",
       "2               7              23            0.958333                 5   \n",
       "3               1               5            0.500000                 1   \n",
       "4               4              32            0.500000                 3   \n",
       "\n",
       "   category_Women  category_Petite  reviewTextNumSents  reviewTextFscore  \\\n",
       "0             1.0              0.0                   4         76.005682   \n",
       "1             1.0              0.0                   4         70.630000   \n",
       "2             1.0              0.0                   4         91.434643   \n",
       "3             0.0              0.0                   7         84.032353   \n",
       "4             0.0              0.0                   3         83.598333   \n",
       "\n",
       "   reviewTextFKscore  \n",
       "0           6.757121  \n",
       "1           4.650000  \n",
       "2           3.114524  \n",
       "3           4.555126  \n",
       "4           6.070741  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_abl_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>price</th>\n",
       "      <th>outOf</th>\n",
       "      <th>nHelpful</th>\n",
       "      <th>pctHelpful</th>\n",
       "      <th>itemTotReviews</th>\n",
       "      <th>avgUserHelpfulness</th>\n",
       "      <th>itemRatedReviews</th>\n",
       "      <th>category_Women</th>\n",
       "      <th>summaryTextNumWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>I134326011</td>\n",
       "      <td>U100860173</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1231632000</td>\n",
       "      <td>53.04</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>4</td>\n",
       "      <td>0.891534</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>I486821863</td>\n",
       "      <td>U071062576</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1330992000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.970149</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>I133591235</td>\n",
       "      <td>U233308558</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1390521600</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>18</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>I399679500</td>\n",
       "      <td>U373444291</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260835200</td>\n",
       "      <td>39.48</td>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>10</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>I360662505</td>\n",
       "      <td>U248389958</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1388016000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         itemID  reviewerID  rating  unixReviewTime  price  outOf  nHelpful  \\\n",
       "43   I134326011  U100860173     5.0      1231632000  53.04     21        19   \n",
       "53   I486821863  U071062576     3.0      1330992000  -1.00     25        24   \n",
       "56   I133591235  U233308558     2.0      1390521600  -1.00     23        22   \n",
       "80   I399679500  U373444291     4.0      1260835200  39.48     51        45   \n",
       "136  I360662505  U248389958     3.0      1388016000  -1.00     40        39   \n",
       "\n",
       "     pctHelpful  itemTotReviews  avgUserHelpfulness  itemRatedReviews  \\\n",
       "43     0.904762               4            0.891534                 2   \n",
       "53     0.960000              12            0.970149                11   \n",
       "56     0.956522              18            0.909091                 8   \n",
       "80     0.882353              10            0.882353                 3   \n",
       "136    0.975000              12            0.989130                10   \n",
       "\n",
       "     category_Women  summaryTextNumWords  \n",
       "43              0.0                    4  \n",
       "53              1.0                    1  \n",
       "56              1.0                    6  \n",
       "80              0.0                   21  \n",
       "136             1.0                    5  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_abl_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>price</th>\n",
       "      <th>outOf</th>\n",
       "      <th>userTotReviews</th>\n",
       "      <th>itemTotReviews</th>\n",
       "      <th>avgItemHelpfulness</th>\n",
       "      <th>userRatedReviews</th>\n",
       "      <th>category_Women</th>\n",
       "      <th>category_Petite</th>\n",
       "      <th>reviewTextNumSents</th>\n",
       "      <th>reviewTextFscore</th>\n",
       "      <th>reviewTextFKscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>76.005682</td>\n",
       "      <td>6.757121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.99</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>70.630000</td>\n",
       "      <td>4.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>19.99</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.434643</td>\n",
       "      <td>3.114524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>84.032353</td>\n",
       "      <td>4.555126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>83.598333</td>\n",
       "      <td>6.070741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  price  outOf  userTotReviews  itemTotReviews  avgItemHelpfulness  \\\n",
       "0     4.0  -1.00      4              17              13            0.800000   \n",
       "1     4.0   9.99      2               3               7            1.000000   \n",
       "2     5.0  19.99      7               7              23            0.958333   \n",
       "3     5.0  -1.00      2               1               5            0.500000   \n",
       "4     5.0  10.00      1               4              32            0.500000   \n",
       "\n",
       "   userRatedReviews  category_Women  category_Petite  reviewTextNumSents  \\\n",
       "0                 9             1.0              0.0                   4   \n",
       "1                 2             1.0              0.0                   4   \n",
       "2                 5             1.0              0.0                   4   \n",
       "3                 1             0.0              0.0                   7   \n",
       "4                 3             0.0              0.0                   3   \n",
       "\n",
       "   reviewTextFscore  reviewTextFKscore  \n",
       "0         76.005682           6.757121  \n",
       "1         70.630000           4.650000  \n",
       "2         91.434643           3.114524  \n",
       "3         84.032353           4.555126  \n",
       "4         83.598333           6.070741  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_abl_1_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>price</th>\n",
       "      <th>outOf</th>\n",
       "      <th>itemTotReviews</th>\n",
       "      <th>avgUserHelpfulness</th>\n",
       "      <th>itemRatedReviews</th>\n",
       "      <th>category_Women</th>\n",
       "      <th>summaryTextNumWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1231632000</td>\n",
       "      <td>53.04</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0.891534</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1330992000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>0.970149</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1390521600</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1260835200</td>\n",
       "      <td>39.48</td>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1388016000</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rating  unixReviewTime  price  outOf  itemTotReviews  avgUserHelpfulness  \\\n",
       "43      5.0      1231632000  53.04     21               4            0.891534   \n",
       "53      3.0      1330992000  -1.00     25              12            0.970149   \n",
       "56      2.0      1390521600  -1.00     23              18            0.909091   \n",
       "80      4.0      1260835200  39.48     51              10            0.882353   \n",
       "136     3.0      1388016000  -1.00     40              12            0.989130   \n",
       "\n",
       "     itemRatedReviews  category_Women  summaryTextNumWords  \n",
       "43                  2             0.0                    4  \n",
       "53                 11             1.0                    1  \n",
       "56                  8             1.0                    6  \n",
       "80                  3             0.0                   21  \n",
       "136                10             1.0                    5  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_abl_2_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final features for model fit to low 'outOf' values:\n",
      "rating\n",
      "price\n",
      "outOf\n",
      "userTotReviews\n",
      "itemTotReviews\n",
      "avgItemHelpfulness\n",
      "userRatedReviews\n",
      "category_Women\n",
      "category_Petite\n",
      "reviewTextNumSents\n",
      "reviewTextFscore\n",
      "reviewTextFKscore\n"
     ]
    }
   ],
   "source": [
    "print(\"final features for model fit to low 'outOf' values:\")\n",
    "for c in X_train_abl_1_num.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final features for model fit to high 'outOf' values:\n",
      "rating\n",
      "unixReviewTime\n",
      "price\n",
      "outOf\n",
      "itemTotReviews\n",
      "avgUserHelpfulness\n",
      "itemRatedReviews\n",
      "category_Women\n",
      "summaryTextNumWords\n"
     ]
    }
   ],
   "source": [
    "print(\"final features for model fit to high 'outOf' values:\")\n",
    "for c in X_train_abl_2_num.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
